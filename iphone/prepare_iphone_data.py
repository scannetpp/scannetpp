
'''
Download ScanNet++ data

Default: download splits with scene IDs and default files
that can be used for novel view synthesis on DSLR and iPhone images
and semantic tasks on the mesh
'''

from omegaconf import DictConfig
import hydra
from pathlib import Path
from tqdm import tqdm
import zlib
import numpy as np
import imageio as iio
import os
import re
import tempfile
import shutil
try:
    import lz4.block
except ImportError:
    print('lz4 not installed, depth extraction will not be available')

from common.scene_release import ScannetppScene_Release
from common.utils.utils import run_command, load_yaml_munch, load_json, read_txt_list
from common.utils.colmap import get_camera_images_poses


def extract_rgb(scene, output_root=None):
    if output_root is None:
        output_dir = scene.iphone_rgb_dir
    else:
        output_scene = ScannetppScene_Release(scene.scene_id, data_root=output_root)
        output_dir = output_scene.iphone_rgb_dir
    output_dir.mkdir(parents=True, exist_ok=True)

    cmd = f"ffmpeg -i {scene.iphone_video_path} -start_number 0 -q:v 1 {output_dir}/frame_%06d.jpg"
    run_command(cmd, verbose=True)

def extract_rgb_in_colmap(scene, output_root):
    '''
    scene: scene object
    output_root: where to put the output frames, if None, put in the scene.iphone_rgb_dir
    '''
    if output_root is None:
        output_dir = scene.iphone_rgb_dir
    else:
        output_scene = ScannetppScene_Release(scene.scene_id, data_root=output_root)
        output_dir = output_scene.iphone_rgb_dir
    output_dir.mkdir(parents=True, exist_ok=True)

    # read colmap
    _, image_list, _, _ = get_camera_images_poses(scene, image_type='iphone')
    print(f'='*100)
    print(f'Num images to extract: {len(image_list)}')
    print(f'='*100)
    # convert to frame indices frame_000000, frame_000001, .. -> [0, 1, 2, ..] and sort 
    frame_indices = sorted([int(image_name.split('_')[-1].split('.')[0]) for image_name in image_list])

    # select='eq(n,0)+eq(n,10)'
    filter_str = "select='" + "+".join([f"eq(n,{i})" for i in frame_indices]) + "'"
    # save to tmp file
    with tempfile.NamedTemporaryFile(mode='w', dir='.', suffix='.txt', delete=False) as tmp:
        tmp.write(filter_str)
    tmp_path = tmp.name

    # first write to a different dir so that we can rename the files later
    output_tmp_dir = output_dir / 'tmp'
    output_tmp_dir.mkdir(parents=True, exist_ok=True)

    cmd = [
        'ffmpeg', '-y', 
        '-i', str(scene.iphone_video_path),
        '-filter_script:v', str(tmp_path),
        '-vsync', 'vfr', 
        '-q:v', '1', 
        str(output_tmp_dir / "frame_%06d.jpg")
    ]
    cmd = ' '.join(cmd)
    try:
        run_command(cmd, verbose=True)
    finally:
        if os.path.exists(tmp_path):
            os.remove(tmp_path)
    # 1. Get all files generated by FFmpeg
    extracted_files = list(output_tmp_dir.glob("frame_*.jpg"))

    # 2. Sort them numerically by the number in the filename
    # This prevents "frame_10.jpg" coming before "frame_2.jpg"
    extracted_files.sort(key=lambda f: int(re.findall(r'\d+', f.name)[0]))

    # 3. Sort your colmap image_list by the frame index as well
    # (Ensuring alignment with the frame_indices you used for the filter)
    sorted_image_list = sorted(image_list, key=lambda x: int(x.split('_')[-1].split('.')[0]))

    # 4. Verify and Rename
    if len(extracted_files) != len(sorted_image_list):
        print(f"Error: Found {len(extracted_files)} frames but expected {len(sorted_image_list)}")
    else:
        print(f"Aligning extracted files {len(extracted_files)} files with colmap image_list {len(sorted_image_list)}")
        for file_path, target_name in zip(extracted_files, sorted_image_list):
            # Rename to the final target name
            final_path = output_dir / target_name
            # move file from tmp dir to output dir and rename to the target name
            shutil.move(file_path, final_path)
        print("Renaming complete.")
        
    pass

    # remove the tmp dir
    shutil.rmtree(output_tmp_dir, ignore_errors=True)


def extract_masks(scene):
    scene.iphone_video_mask_dir.mkdir(parents=True, exist_ok=True)
    cmd = f"ffmpeg -i {str(scene.iphone_video_mask_path)} -pix_fmt gray -start_number 0 {scene.iphone_video_mask_dir}/frame_%06d.png"
    run_command(cmd, verbose=True)

def extract_depth(scene):
    # global compression with zlib
    height, width = 192, 256
    sample_rate = 1
    scene.iphone_depth_dir.mkdir(parents=True, exist_ok=True)

    try:
        with open(scene.iphone_depth_path, 'rb') as infile:
            data = infile.read()
            data = zlib.decompress(data, wbits=-zlib.MAX_WBITS)
            depth = np.frombuffer(data, dtype=np.float32).reshape(-1, height, width)

        for frame_id in tqdm(range(0, depth.shape[0], sample_rate), desc='decode_depth'):
            iio.imwrite(f"{scene.iphone_depth_dir}/frame_{frame_id:06}.png", (depth * 1000).astype(np.uint16))
    # per frame compression with lz4/zlib
    except:
        frame_id = 0
        with open(scene.iphone_depth_path, 'rb') as infile:
            while True:
                size = infile.read(4)   # 32-bit integer
                if len(size) == 0:
                    break
                size = int.from_bytes(size, byteorder='little')
                if frame_id % sample_rate != 0:
                    infile.seek(size, 1)
                    frame_id += 1
                    continue

                # read the whole file
                data = infile.read(size)
                try:
                    # try using lz4
                    data = lz4.block.decompress(data, uncompressed_size=height * width * 2)  # UInt16 = 2bytes
                    depth = np.frombuffer(data, dtype=np.uint16).reshape(height, width)
                except:
                    # try using zlib
                    data = zlib.decompress(data, wbits=-zlib.MAX_WBITS)
                    depth = np.frombuffer(data, dtype=np.float32).reshape(height, width)
                    depth = (depth * 1000).astype(np.uint16)

                # 6 digit frame id = 277 minute video at 60 fps
                iio.imwrite(f"{scene.iphone_depth_dir}/frame_{frame_id:06}.png", depth)
                frame_id += 1

@hydra.main(version_base=None, config_path="configs", config_name='prepare_iphone_data')
def main(cfg : DictConfig) -> None:
    print(f'Config: {cfg}')

    # get the scenes to process, specify any one
    if cfg.get('scene_list_file'):
        scene_ids = read_txt_list(cfg.scene_list_file)
    elif cfg.get('scene_ids'):
        scene_ids = cfg.scene_ids
    elif cfg.get('splits'):
        scene_ids = []
        for split in cfg.splits:
            split_path = Path(cfg.data_root) / 'splits' / f'{split}.txt'
            scene_ids += read_txt_list(split_path)

    # get the options to process
    # go through each scene
    for scene_id in tqdm(scene_ids, desc='scene'):
        scene = ScannetppScene_Release(scene_id, data_root=Path(cfg.data_root) / 'data')

        if cfg.extract_rgb:
            if cfg.extract_only_rgb_in_colmap:
                # extract only the frames that are in colmap images.txt
                extract_rgb_in_colmap(scene, output_root=cfg.output_root)
            else:
                # extract all frames
                extract_rgb(scene, output_root=cfg.output_root)

        if cfg.extract_masks:
            extract_masks(scene)

        if cfg.extract_depth:
            extract_depth(scene)

if __name__ == '__main__':
    main()